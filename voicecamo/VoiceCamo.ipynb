{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3PeBPDbn1dp",
        "outputId": "b6f8e6a6-dd83-4e5b-a098-d115d549d09a"
      },
      "outputs": [],
      "source": [
        "# Execute this code block to install dependencies when running on colab\n",
        "try:\n",
        "    import torch\n",
        "except:\n",
        "    from os.path import exists\n",
        "    from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "    platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "    cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "    accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "    ! pip install -q http://download.pytorch.org/whl/{accelerator}/torch-1.0.0-{platform}-linux_x86_64.whl torchvision\n",
        "\n",
        "try: \n",
        "    import torchbearer\n",
        "except:\n",
        "    ! pip install torchbearer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "FTwHm3pPkWuU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import torchbearer\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchaudio.datasets import LIBRISPEECH\n",
        "from torchbearer import Trial\n",
        "import numpy as np\n",
        "import torchaudio\n",
        "import torchaudio.functional as Fa\n",
        "import torchaudio.transforms as T\n",
        "import scipy as sp\n",
        "from scipy import signal\n",
        "import pytorch_lightning as pl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "-M2BOauYkZmy"
      },
      "outputs": [],
      "source": [
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "torch.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "7IwRX3vdxJit"
      },
      "outputs": [],
      "source": [
        "# load data\n",
        "trainset = LIBRISPEECH(\".\", download=True)\n",
        "testset = LIBRISPEECH(\".\", download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mi4co7Vy2M3_",
        "outputId": "1a6f7e24-403f-4dae-a9d4-d6f20baacdfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "28539   161\n"
          ]
        }
      ],
      "source": [
        "n = len(trainset)\n",
        "nn = 161\n",
        "print(n , \" \", nn)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OwMBCn8Dq8DD"
      },
      "source": [
        "The out to our network is the Short-Term Fourier Transform (STFT) of the last 2 seconds of the\n",
        "speech signal.\n",
        "\n",
        "To calculate the STFT:\n",
        "\n",
        "*   we use a hamming window length of 320 samples\n",
        "*   hop length of 160 samples\n",
        "*   FFT size of 320\n",
        "\n",
        "Resulting in an **out dimension** of 2 × 161 × 204. \n",
        "\n",
        "We use a 13 layer convolutional network.\n",
        "\n",
        "The network outputs a waveform of 0.5 seconds, sampled at 16kHz. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "28539\n",
            "tensor([[-0.0065, -0.0055, -0.0062,  ...,  0.0033,  0.0005, -0.0095]])\n"
          ]
        }
      ],
      "source": [
        "# trainloader = DataLoader(stftTrainSet, batch_size=32, shuffle=True)\n",
        "print(len(trainset))\n",
        "print(trainset[0][0])\n",
        "# it = iter(trainloader)\n",
        "# print(next(it)[0])\n",
        "# print(next(it)[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([161, 201])\n"
          ]
        }
      ],
      "source": [
        "stftTrainSet = torch.zeros(n, 161, 201)\n",
        "# print(stftTrainSet)\n",
        "i=0\n",
        "for s in trainset :\n",
        "  # print(s[2])\n",
        "  # print(len(s))\n",
        "  short = s[0][:, -s[1]*2 :] # takes last 2 seconds\n",
        "  if short.size() != nn:\n",
        "    short = torch.from_numpy(np.pad(short, [(0, 0), (0, 32000 - [*short.size()][1])], 'constant'))\n",
        "  stftTrainSet[i]=(torch.stft(short, n_fft=320, hop_length=160, win_length=320, window=torch.hann_window(320), center=True, pad_mode=\"reflect\", return_complex=True ))\n",
        "  i += 1\n",
        "\n",
        "print(stftTrainSet[0].shape)\n",
        "trainloader = DataLoader(stftTrainSet, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "892\n",
            "tensor([[-5.0163e-01, -4.1474e-01, -4.1267e-01,  ...,  1.5079e-01,\n",
            "          1.5291e-01, -4.0820e-02],\n",
            "        [ 2.9828e-01,  1.9604e-01,  2.1379e-01,  ..., -7.3055e-02,\n",
            "         -9.7550e-02,  1.1011e-01],\n",
            "        [-9.4276e-02,  9.0133e-03,  5.5531e-03,  ..., -1.5590e-02,\n",
            "          3.4145e-02, -1.2937e-01],\n",
            "        ...,\n",
            "        [-6.7391e-04,  1.7671e-03, -4.4277e-04,  ...,  1.0176e-03,\n",
            "         -2.2972e-04,  5.9798e-04],\n",
            "        [ 2.4803e-04, -1.3281e-03, -2.7625e-04,  ..., -1.0205e-03,\n",
            "         -3.5502e-05, -9.1248e-04],\n",
            "        [-1.6239e-04,  1.0773e-03,  8.9604e-04,  ...,  1.4257e-03,\n",
            "          1.3685e-04,  8.5086e-04]])\n",
            "tensor([[ 1.0264e+00, -1.4137e-01, -1.5015e-01,  ..., -1.6829e-03,\n",
            "         -5.4164e-03,  3.0341e-02],\n",
            "        [-1.5221e+00, -8.0741e-01, -6.4040e-01,  ...,  9.8537e-03,\n",
            "          3.8811e-03, -4.3285e-02],\n",
            "        [-1.7463e-01,  3.0923e+00,  2.4873e+00,  ..., -2.9448e-02,\n",
            "          1.8498e-02,  5.3689e-02],\n",
            "        ...,\n",
            "        [ 9.5461e-04, -3.0313e-03, -6.1324e-03,  ..., -4.2405e-04,\n",
            "         -5.1329e-05,  7.2028e-04],\n",
            "        [ 2.6751e-03, -2.9501e-03,  6.9428e-03,  ...,  1.0875e-03,\n",
            "          7.5834e-05,  3.5425e-04],\n",
            "        [-2.9923e-03,  6.7592e-03, -2.9890e-03,  ..., -1.1237e-03,\n",
            "         -3.5716e-04, -1.1389e-03]])\n"
          ]
        }
      ],
      "source": [
        "print(len(trainset))\n",
        "print(trainset[0][0])\n",
        "trainloader = DataLoader(stftTrainSet, batch_size=32, shuffle=True)\n",
        "print(len(trainloader))\n",
        "it = iter(trainloader)\n",
        "print(next(it)[0])\n",
        "print(next(it)[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0cl_CP5jULf",
        "outputId": "dda4fab8-d3bf-4131-bac1-31f439aa9327"
      },
      "outputs": [],
      "source": [
        "# shortTestSet = np.empty([n,nn])\n",
        "# print(shortTestSet)\n",
        "\n",
        "# i=0\n",
        "\n",
        "# for s in testset :\n",
        "\n",
        "#   short = s[0][:, -s[1]*2 :]\n",
        "#   if short.size() != nn:\n",
        "#     short = np.pad(short, [(0, 0), (0, 32000 - [*short.size()][1])], 'constant')\n",
        "#   shortTestSet[i] = signal.stft(short, nperseg = 320, noverlap = 160, nfft = 320)[0]\n",
        "#   i += 1\n",
        "\n",
        "# print(shortTestSet)\n",
        "# testset = torch.from_numpy(shortTestSet)\n",
        "# del shortTestSet\n",
        "# print(testset)\n",
        "# testloader = DataLoader(testset, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVEfE---_WXM"
      },
      "source": [
        "The learning rate started at 1.5 * $10^4$ and decreased using an exponential learning rate scheduler, with a learning anneal gamma value of 0.99."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "wL9Dalg-rBQJ"
      },
      "source": [
        "A.2 NETWORK ARCHITECTURE\n",
        "\n",
        "The architecture is comprised of :\n",
        "\n",
        "* 8 down-sampling convolutional blocks \n",
        "* 4 up-sampling convolutional blocks \n",
        "* linear layer\n",
        "\n",
        "The down-sampling convolutional block is comprised of a reflection padding, followed a 2d convolution layer, followed by a 2d batch norm, followed by a prelu activation function. The first\n",
        "downsampling block has 64 channels, the second through the seventh have 128, and finally the last\n",
        "one has 256 channels. \n",
        "\n",
        "**The last conv block also has a leaky relu instead of prelu. Here the signal is\n",
        "reshaped into a one-hot vector.**\n",
        "\n",
        "The upsampling blocks are comprised of 1-dimensional ConvTranspose 1d, and a leaky relu activation function. The first has 64 channels, the second 32, the third 16, the fourth, 1. Finally, the linear\n",
        "layer is followed by a tanh activation function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "gCvkuHnskdp3"
      },
      "outputs": [],
      "source": [
        "class CamoCNN(pl.LightningModule):\n",
        "    def __init__(self):\n",
        "        super(CamoCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 64, (5,5), padding=0)\n",
        "        self.conv2 = nn.Conv2d(64, 128, (5,5), padding=0)\n",
        "        self.conv3 = nn.Conv2d(128, 128, (5,5), padding=0)\n",
        "        self.conv4 = nn.Conv2d(128, 128, (5,5), padding=0)\n",
        "        self.conv5 = nn.Conv2d(128, 128, (5,5), padding=0)\n",
        "        self.conv6 = nn.Conv2d(128, 128, (5,5), padding=0)\n",
        "        self.conv7 = nn.Conv2d(128, 128, (5,5), padding=0)\n",
        "        self.conv8 = nn.Conv2d(128, 256, (5,5), padding=0)\n",
        "\n",
        "        self.convTrans1 = nn.ConvTranspose1d(256, 64, (5,5), padding=0)\n",
        "        self.convTrans2 = nn.ConvTranspose1d(64, 32, (5,5), padding=0)\n",
        "        self.convTrans3 = nn.ConvTranspose1d(32, 16, (5,5), padding=0)\n",
        "        self.convTrans4 = nn.ConvTranspose1d(16, 1, (5,5), padding=0)\n",
        "        # ouutput from the convolution layer is 1+ (16+0-5)/1 = 12\n",
        "        self.fc1 = nn.Linear(12, 1)\n",
        "            \n",
        "    def forward(self, input):\n",
        "       \n",
        "      # DOWN-SAMPLING BLOCKS\n",
        "\n",
        "      out = F.pad(input, pad=(2,2,2,2), mode='reflect')\n",
        "      out = self.conv1(out)\n",
        "      out = F.batch_norm(out)\n",
        "      out = F.prelu(out)\n",
        "\n",
        "      out = F.pad(out, pad=(2,2,2,2), mode='reflect')\n",
        "      out = self.conv2(out)\n",
        "      out = F.batch_norm(out)\n",
        "      out = F.prelu(out)\n",
        "\n",
        "      out = F.pad(out, pad=(2,2,2,2), mode='reflect')\n",
        "      out = self.conv3(out)\n",
        "      out = F.batch_norm(out)\n",
        "      out = F.prelu(out)\n",
        "\n",
        "      out = F.pad(out, pad=(2,2,2,2), mode='reflect')\n",
        "      out = self.conv4(out)\n",
        "      out = F.batch_norm(out)\n",
        "      out = F.prelu(out)\n",
        "\n",
        "      out = F.pad(out, pad=(2,2,2,2), mode='reflect')\n",
        "      out = self.conv5(out)\n",
        "      out = F.batch_norm(out)\n",
        "      out = F.prelu(out)\n",
        "\n",
        "      out = F.pad(out, pad=(2,2,2,2), mode='reflect')\n",
        "      out = self.conv6(out)\n",
        "      out = F.batch_norm(out)\n",
        "      out = F.prelu(out)\n",
        "\n",
        "      out = F.pad(out, pad=(2,2,2,2), mode='reflect')\n",
        "      out = self.conv7(out)\n",
        "      out = F.batch_norm(out)\n",
        "      out = F.prelu(out)\n",
        "\n",
        "      out = F.pad(out, pad=(2,2,2,2), mode='reflect')\n",
        "      out = self.conv8(out)\n",
        "      out = F.batch_norm(out) \n",
        "      out = F.leaky_relu(out)\n",
        "\n",
        "      out = out.view(out.shape[0], -1)\n",
        "\n",
        "      #UP-SAMPLING BLOCKS\n",
        "      out = self.convTrans1(out)\n",
        "      out = F.leaky_relu(out)\n",
        "\n",
        "      out = self.convTrans2(out)\n",
        "      out = F.leaky_relu(out)\n",
        "\n",
        "      out = self.convTrans3(out)\n",
        "      out = F.leaky_relu(out)\n",
        "\n",
        "      out = self.convTrans4(out)\n",
        "      out = F.leaky_relu(out)\n",
        "\n",
        "      #LINEAR LAYER\n",
        "      out = self.fc1(out)\n",
        "      out = F.tanh(out)\n",
        "\n",
        "      return out\n",
        "    \n",
        "    def loss_fn(self,out,target):\n",
        "      return nn.CTCLoss()(out, target, out.size, target.size)\n",
        "    \n",
        "    def configure_optimizers(self):\n",
        "      LR = 1.5*10**(-4)\n",
        "      gamma = 0.99\n",
        "      optimizer = torch.optim.lr_scheduler.ExponentialLR(optimizer=torch.optim.SGD(self.parameters(),lr=LR), gamma=gamma)\n",
        "      return optimizer\n",
        "\n",
        "    def training_step(self,batch,target):\n",
        "      \n",
        "      x, y = batch\n",
        "      # print(x,target)\n",
        "      prediction = self(x)\n",
        "      # print(prediction)\n",
        "      loss = self.loss_fn(target,prediction)\n",
        "      self.log('train_loss', loss)\n",
        "      return loss       \n",
        "\n",
        "    def validation_step(self,batch,target):\n",
        "      x, y = batch\n",
        "      prediction = self(x)\n",
        "      loss = self.loss_fn(target,prediction)\n",
        "      prediction = nn.Softmax(-1)(prediction) \n",
        "      logits = torch.argmax(prediction,dim=1)\n",
        "      accu = self.accuracy(logits, target)        \n",
        "      self.log('valid_loss', loss)\n",
        "      self.log('train_acc_step', accu)\n",
        "      return loss, accu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'int' object has no attribute 'Conv2d'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m CamoCNN()\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(model\u001b[39m.\u001b[39mtraining_step(trainloader))\n",
            "Cell \u001b[0;32mIn[56], line 4\u001b[0m, in \u001b[0;36mCamoCNN.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[39msuper\u001b[39m(CamoCNN, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[0;32m----> 4\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1 \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mConv2d(\u001b[39m1\u001b[39m, \u001b[39m64\u001b[39m, (\u001b[39m5\u001b[39m,\u001b[39m5\u001b[39m), padding\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2 \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mConv2d(\u001b[39m64\u001b[39m, \u001b[39m128\u001b[39m, (\u001b[39m5\u001b[39m,\u001b[39m5\u001b[39m), padding\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m      6\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv3 \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mConv2d(\u001b[39m128\u001b[39m, \u001b[39m128\u001b[39m, (\u001b[39m5\u001b[39m,\u001b[39m5\u001b[39m), padding\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'Conv2d'"
          ]
        }
      ],
      "source": [
        "model = CamoCNN()\n",
        "print(model.training_step(trainloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'Camo' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m CamoCNN()\n\u001b[1;32m      3\u001b[0m trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mTrainer(gpus\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, max_epochs\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, deterministic\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m trainer\u001b[39m.\u001b[39mfit(model, trainloader)\n",
            "Cell \u001b[0;32mIn[8], line 3\u001b[0m, in \u001b[0;36mCamoCNN.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     \u001b[39msuper\u001b[39m(Camo, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[1;32m      4\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1 \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mConv2d(\u001b[39m1\u001b[39m, \u001b[39m64\u001b[39m, (\u001b[39m5\u001b[39m,\u001b[39m5\u001b[39m), padding\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2 \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mConv2d(\u001b[39m64\u001b[39m, \u001b[39m128\u001b[39m, (\u001b[39m5\u001b[39m,\u001b[39m5\u001b[39m), padding\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Camo' is not defined"
          ]
        }
      ],
      "source": [
        "model = CamoCNN()\n",
        "\n",
        "trainer = pl.Trainer(gpus=1, max_epochs=100, deterministic=True)\n",
        "\n",
        "trainer.fit(model, trainloader)\n",
        "trainer.test(model, testloader)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In order to train our model, we need to compute the loss between the predicted speech and the ground-truth speech, \n",
        "\n",
        "meaning that in training, we need to attack the entire speech signal, not just a small segment. \n",
        "\n",
        "We therefore need to schedule our forward and backward passes such that we have computed the attack for the entire\n",
        "segment before we calculate the gradients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [],
      "source": [
        "Epoch = 4\n",
        "learningRate = 1.5*10**(-4)\n",
        "gamma = 0.99"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# build the model\n",
        "model = CamoCNN()\n",
        "\n",
        "# define the loss function and the optimiser\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimiser = optim.Adam(model.parameters())\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "trial = Trial(model, optimiser, loss_function, metrics=['loss', 'accuracy']).to(device)\n",
        "trial.with_generators(trainloader, test_generator=testloader)\n",
        "trial.run(epochs=10)\n",
        "results = trial.evaluate(data_key=torchbearer.TEST_DATA)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
